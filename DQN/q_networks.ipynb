{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "#import tflearn\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Q_Network(object):\n",
    "    def __init__(self, info):\n",
    "        self.graph = graph\n",
    "        self.dim_s = info.dim_s\n",
    "        self.dim_a = info.dim_a\n",
    "        self.hid_layers = info.hid_layers\n",
    "        #self.epsilon = info.epsilon\n",
    "        \n",
    "        self.learning_rate = tf.placeholder(tf.float32)\n",
    "        self.inputs = tf.placeholder(shape=[None, self.dim_s], dtype=tf.float32)\n",
    "        with tf.name_scope(\"model\"):\n",
    "            self.q_values = self.create_net()\n",
    "            \n",
    "        with tf.name_scope(\"target\"):\n",
    "            self.target_q_values = self.create_net()\n",
    "            \n",
    "        self.greedy_action = tf.argmax(self.q_values, axis=1)\n",
    "        self.target_q_max = tf.reduce_max(self.target_q_values, reduction_indices=[1])\n",
    "        self.R = tf.placeholder(tf.float32, [None])\n",
    "        self.taken_action = tf.placeholder(tf.int32, [None])\n",
    "        self.one_hot_action = tf.one_hot(self.taken_action, self.dim_a, dtype=tf.float32)\n",
    "        \n",
    "        self.q_a = tf.reduce_sum(self.q_values * self.one_hot_action, [1]) \n",
    "        self.loss = tf.reduce_mean(tf.square(self.R - self.q_a))\n",
    "        self.optimize = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
    "        \n",
    "        # Updating the target net\n",
    "        from_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"model\")\n",
    "        to_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'target')\n",
    "\n",
    "        update_ops = [] # this list_op must be run to update\n",
    "        for from_var,to_var in zip(from_vars,to_vars):\n",
    "            update_ops.append(to_var.assign(from_var))\n",
    "        \n",
    "        \n",
    "    def create_net(self):\n",
    "        \n",
    "        w_1 = tf.Variable(tf.truncated_normal([self.dim_s, self.hid_layers[0]]))\n",
    "        b_1 = tf.Variable(tf.zeros([self.hid_layers[0]]))\n",
    "        inputs_1 = tf.matmul(self.inputs, w_1) + b_1\n",
    "        net = tf.nn.tanh(inputs_1)\n",
    "        \n",
    "        if(len(self.hid_layers) > 1):\n",
    "            w_2 = tf.Variable(tf.truncated_normal([self.hid_layers[0], self.hid_layers[1]]))\n",
    "            b_2 = tf.Variable(tf.zeros([self.hid_layers[1]]))\n",
    "            inputs_2 = tf.matmul(self.out_1, w_2) + b_2\n",
    "            net = tf.nn.tanh(inputs_2)\n",
    "        \n",
    "        w_3 = tf.Variable(tf.truncated_normal([self.hid_layers[-1], self.dim_a]))\n",
    "        b_3 = tf.Variable(tf.zeros([self.dim_a]))\n",
    "        q_value = tf.matmul(net, w_3) + b_3\n",
    "        \n",
    "        return q_value\n",
    "    \n",
    "    def set_up(self, sess):\n",
    "        self.sess = sess\n",
    "        \n",
    "    def target_q(self, inputs, actions):\n",
    "        \n",
    "        return self.sess.run([self.taget_q_max], feed_dict={\n",
    "            self.inputs: inputs,\n",
    "            self.a: actions\n",
    "        })\n",
    "    \n",
    "    def train(self, inputs, actions, R, lr_rate):\n",
    "        \n",
    "        return self.sess.run([self.loss, self.opmtize], feed_dict={\n",
    "            self.inputs: inputs,\n",
    "            self.a: actions,\n",
    "            self.R: R,\n",
    "            self.learnign_rate: lr_rate\n",
    "        })\n",
    "        \n",
    "    def take_action(self, inputs, epsilon):\n",
    "        \n",
    "        gr_action = self.sess.run(self.greedy_action, feed_dict={\n",
    "            self.inputs: inputs\n",
    "        })\n",
    "        \n",
    "        if (epsilon > random.random()):\n",
    "            action = np.random.choice(self.dim_a)\n",
    "        else:\n",
    "            action = gr_action\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    def update_target(self):\n",
    "        self.sess.run(update_ops)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
